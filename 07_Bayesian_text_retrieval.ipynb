{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO2PdX/lxGKqTRlo4XyMwvC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2023-stats1/blob/main/07_Bayesian_text_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Text Retrieval"
      ],
      "metadata": {
        "id": "ECnVmMCn7SqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ランタイムのタイプをGPUにしておく**"
      ],
      "metadata": {
        "id": "YnIQekV2p3bU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備"
      ],
      "metadata": {
        "id": "VrgoYRSB8LW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### インポート"
      ],
      "metadata": {
        "id": "ClYQyl5JXLuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "Gk0bNQ9Mp_vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データセット"
      ],
      "metadata": {
        "id": "bJrqfKPu8Maq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus, train_labels = fetch_20newsgroups(subset=\"train\", return_X_y=True)\n",
        "test_corpus, test_labels = fetch_20newsgroups(subset=\"test\", return_X_y=True)\n",
        "print(f\"training size: {len(train_corpus)}\\ntest size: {len(test_corpus)}\")"
      ],
      "metadata": {
        "id": "NzCwCI7IqB9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 単語の出現回数を数える"
      ],
      "metadata": {
        "id": "ZJae3CD4rNX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(min_df=10, stop_words=\"english\")\n",
        "X_train = vectorizer.fit_transform(train_corpus).toarray()\n",
        "X_test = vectorizer.transform(test_corpus).toarray()\n",
        "vocabulary = vectorizer.get_feature_names_out()\n",
        "print(f\"vocabulary size: {len(vocabulary)}\")"
      ],
      "metadata": {
        "id": "pvdC3n8zqFuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (A) MAP推定（スムージング）"
      ],
      "metadata": {
        "id": "AxV7fi2To5Px"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下は、授業で使ったnotebookからの抜粋。\n",
        "\n",
        "---\n",
        "* クエリの尤度を、各文書について求めた単語確率を使って計算する。\n",
        "  * $n_{q,w}$: クエリ$q$における単語$w$の出現頻度\n",
        "  * このとき、文書$d$の単語確率を使ったクエリ$q$の対数尤度は、以下の通り。\n",
        "$$\\begin{align}\n",
        "L_q(d) = \\sum_w n_{q,w} \\log \\phi_{d,w}\n",
        "\\end{align}$$\n",
        "  * 上の式で、規格化定数の部分は省略している。（ランキングに関係しないため。）\n",
        "* このように計算されたクエリの尤度によって、検索対象の文書をソートする。\n",
        "  * $L_q(d)$が大きい順に、文書を検索結果として表示する。\n",
        "---\n",
        "\n",
        "* 上の説明にある$L_q(d)$の式の計算を、高速化する。\n",
        "* $L_q(d)$の式の計算は、単に、内積の計算をしているだけ。\n",
        "  * クエリ文書の単語の出現回数と・・・\n",
        "  * 訓練文書の単語確率の対数をとったものとで・・・\n",
        "  * 内積の計算をしているだけ。\n",
        "* ということは・・・\n",
        "* 全テスト文書について、各訓練文書について推定された単語確率で尤度を求めることは、行列の積として書ける。\n",
        "* 今回は、GPUも使って、高速化する。"
      ],
      "metadata": {
        "id": "NAAjHXMVo2lO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 下のMAP推定は、ディリクレ事前分布を対称なディリクレ分布とし、\n",
        "* さらにそのパラメータ$\\beta_w$をすべて1.01と設定する場合に相当する。"
      ],
      "metadata": {
        "id": "JqRxmPGeNRns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\hat{\\phi}_w = \\frac{c_w + \\beta_w - 1}{\\sum_w (c_w + \\beta_w - 1)}\n",
        "$$"
      ],
      "metadata": {
        "id": "VAlqN4WNNoPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ディリクレ事前分布のパラメータ\n",
        "beta = 0.01 + 1.0\n",
        "\n",
        "X_train = X_train + beta - 1.0\n",
        "X_train_probs = X_train / X_train.sum(axis=1).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "1xKe491o5eje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### クエリの対数尤度を計算するヘルパ関数\n",
        "* PyTorchを使って、GPU上で計算する。"
      ],
      "metadata": {
        "id": "-bxaiIDqq-zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def log_likelihood(x_test, x_train_prob):\n",
        "  return torch.matmul(\n",
        "      torch.tensor(x_test, dtype=torch.float32, device=\"cuda\"),\n",
        "      torch.log(torch.tensor(x_train_prob, dtype=torch.float32, device=\"cuda\")).t()\n",
        "  ).cpu().numpy()"
      ],
      "metadata": {
        "id": "mrTNOUMu17fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 検索の実行"
      ],
      "metadata": {
        "id": "CXa-pxljtZMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 全てのtest文書について、その尤度を最大にするtraining文書を求める。"
      ],
      "metadata": {
        "id": "93qv9D1-t-Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = log_likelihood(X_test, X_train_probs)"
      ],
      "metadata": {
        "id": "P-8knQc0qzRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_train_indices = (- scores).argsort(-1)"
      ],
      "metadata": {
        "id": "orGJTgOSpXrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_ranked_train_docs = sorted_train_indices[:,0].reshape(-1)\n",
        "print(top_ranked_train_docs)"
      ],
      "metadata": {
        "id": "05cXC360pf7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* P@1はprecision at oneの略。\n",
        "  * https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Precision_at_k"
      ],
      "metadata": {
        "id": "EFsEN7nNtAhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"P@1={(test_labels == train_labels[top_ranked_train_docs]).sum()/len(test_labels):.3f}\")"
      ],
      "metadata": {
        "id": "veu4K7svpngo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 最上位にランキングされた訓練文書がテスト文書と同じカテゴリになっている割合は、0.7ぐらい。"
      ],
      "metadata": {
        "id": "ilz8m-99vhbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `beta`をチューニングする。"
      ],
      "metadata": {
        "id": "4lsjrEqYb4sP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (B) ベイズ推測\n",
        "* 予測分布（＝ディリクレ多項分布）を利用してクエリの予測確率を求める。"
      ],
      "metadata": {
        "id": "oFeO_566K-my"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 授業資料より式を下に転載。\n",
        "  * $\\mathbf{x}$のところに検索対象のテキストを代入して、クエリ$\\mathbf{x}_0$の予測確率を計算する。\n",
        "  * $c_{\\mathbf{x},w}$は検索対象のテキストにおける単語$w$の出現回数を表す。\n",
        "  * $c_{\\mathbf{x}_0,w}$はクエリにおける単語$w$の出現回数を表す。"
      ],
      "metadata": {
        "id": "ZbF0UVJmcOeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "p(\\mathbf{x}_0|\\mathbf{x};\\mathbf{\\beta})\n",
        "= \\frac{n_0! \\Gamma(\\sum_{w=1}^W (c_{\\mathbf{x},w} + \\beta_w))}{\\Gamma( \\sum_{w=1}^W (c_{\\mathbf{x},w} + c_{\\mathbf{x}_0,w} + \\beta_w) )}\n",
        "\\prod_{w=1}^W\n",
        "\\frac{\\Gamma(c_{\\mathbf{x},w} + c_{\\mathbf{x}_0,w}+\\beta_w)}{c_{\\mathbf{x}_0,w}!\\Gamma(c_{\\mathbf{x},w} + \\beta_w)}\n",
        "$$"
      ],
      "metadata": {
        "id": "HxvdGLKALA80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 上の式で、$\\mathbf{x}_0$がクエリに相当する。\n",
        "  * よって、$\\mathbf{x}_0$だけに依存する項は、検索対象のテキストのランク付けには無関係。\n",
        "* ディリクレ事前分布は対称ディリクレ分布だと仮定する。\n",
        "  * つまり、すべての$w$について$\\beta_w = \\beta$と、同じ値$\\beta$を取ると仮定する。"
      ],
      "metadata": {
        "id": "ISVwq0j5LkM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 以上を踏まえて、テキスト$\\mathbf{x}$を使って算出されるクエリ$\\mathbf{x}_0$の対数予測確率を書き下す。\n",
        "  * テキスト$\\mathbf{x}$の長さを$l_{\\mathbf{x}}$と書くことにする。"
      ],
      "metadata": {
        "id": "0kq2wNifMnQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\ln p(\\mathbf{x}_0|\\mathbf{x}_i;\\mathbf{\\beta})\n",
        "= \\ln \\Gamma(l_\\mathbf{x} + W\\beta) - \\ln \\Gamma( l_\\mathbf{x} + l_{\\mathbf{x}_0} + W \\beta )\n",
        "+ \\sum_{w=1}^W \\big(\n",
        "\\ln \\Gamma(c_{\\mathbf{x}, w}+c_{\\mathbf{x}_0,w}+\\beta_w) - \\ln \\Gamma(c_{\\mathbf{x}, w} + \\beta_w) \\big) + const.\n",
        "$$"
      ],
      "metadata": {
        "id": "YRwSFh9nL2BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "X_train_cuda = torch.tensor(X_train, dtype=torch.float32, device=\"cuda\")\n",
        "train_len = X_train_cuda.sum(-1)\n",
        "X_test_cuda = torch.tensor(X_test, dtype=torch.float32, device=\"cuda\")\n",
        "test_len = X_test_cuda.sum(-1)"
      ],
      "metadata": {
        "id": "xn5GdTAcP2kU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 定数の設定"
      ],
      "metadata": {
        "id": "zFdain5oT9ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beta = 0.01 #対称ディリクレ事前分布のパラメータ\n",
        "vocab_size = X_train.shape[-1]"
      ],
      "metadata": {
        "id": "kk3tsO1TQq_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* $\\ln \\Gamma(l_\\mathbf{x} + W\\beta)$を計算する。"
      ],
      "metadata": {
        "id": "rV27by0fTRxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lgamma_all = torch.lgamma(train_len + X_train.shape[-1] * beta)"
      ],
      "metadata": {
        "id": "T7zZ-nNsTTl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* $l_\\mathbf{x} + l_{\\mathbf{x}_0}$をブロードキャストで計算する。\n",
        "  * 検索対象のテキストとテスト用テキスト（クエリとして使用）の\n",
        "  * すべての組み合わせについて\n",
        "  * 二つのテキストの長さの和を求める。"
      ],
      "metadata": {
        "id": "ftmR-9gwTjez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_train_len = train_len + test_len.unsqueeze(1)"
      ],
      "metadata": {
        "id": "nFi-w3AZR38P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* $\\ln \\Gamma( l_\\mathbf{x} + l_{\\mathbf{x}_0} + W \\beta )$を計算する。"
      ],
      "metadata": {
        "id": "vuqv4xQjTLtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgamma_len = torch.lgamma(test_train_len + vocab_size * beta)"
      ],
      "metadata": {
        "id": "-pK-6YiaTAa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgamma_len.shape"
      ],
      "metadata": {
        "id": "gT09zsGtWZIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* $\\ln \\Gamma(c_{\\mathbf{x}, w} + \\beta_w)$を計算する。"
      ],
      "metadata": {
        "id": "EQUlEQeDTdSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lgamma_word = torch.lgamma(X_train_cuda + beta)"
      ],
      "metadata": {
        "id": "zvJbkxw1TfQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* $\\ln \\Gamma(l_\\mathbf{x} + W\\beta)\n",
        "- \\sum_{w=1}^W\n",
        "\\ln \\Gamma(c_{\\mathbf{x}, w} + \\beta_w)$を計算する。"
      ],
      "metadata": {
        "id": "xRa_GgVdUhxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lgamma = train_lgamma_all - train_lgamma_word.sum(-1)"
      ],
      "metadata": {
        "id": "jN2Ev2dnQc3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lgamma.shape"
      ],
      "metadata": {
        "id": "UN4EK2_1Q7xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* $c_{\\mathbf{x}, w}+c_{\\mathbf{x}_0,w}$をブロードキャストで計算する。"
      ],
      "metadata": {
        "id": "h6aqyXo7VEi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#X_sum = X_train_cuda + X_test_cuda.unsqueeze(1)"
      ],
      "metadata": {
        "id": "j7QqfFWDVEPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* メモリが溢れてしまうので、ミニバッチ方式で計算することにする。"
      ],
      "metadata": {
        "id": "TJj0t0noVapH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def log_pred_prob(idx1, idx2):\n",
        "  X_sum = X_train_cuda + X_test_cuda[idx1:idx2].unsqueeze(1) + beta\n",
        "  log_prob = train_lgamma.reshape(1, -1) - lgamma_len[idx1:idx2]\n",
        "  log_prob = log_prob + torch.lgamma(X_sum).sum(-1)\n",
        "  return log_prob"
      ],
      "metadata": {
        "id": "WmlsAx41OdNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "cnt = 0\n",
        "for idx in tqdm(range(0, X_test.shape[0], BATCH_SIZE)):\n",
        "  sorted_train_indices = (- log_pred_prob(idx, idx+BATCH_SIZE)).argsort(-1)\n",
        "  top_ranked_train_docs = sorted_train_indices[:,0].reshape(-1)\n",
        "  cnt += (test_labels[idx:idx+BATCH_SIZE] == train_labels[top_ranked_train_docs.cpu()]).sum()"
      ],
      "metadata": {
        "id": "AV5jYI0jWokA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"P@1={cnt / len(test_labels):.3f}\")"
      ],
      "metadata": {
        "id": "qatQw9bPbjT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `beta`をチューニングする。"
      ],
      "metadata": {
        "id": "ze90ZcqjbvKj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2XBAfmWobtN8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}